{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324abfa0",
   "metadata": {
    "id": "324abfa0"
   },
   "source": [
    "<div >\n",
    "    <img src = \"../Banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dd7af",
   "metadata": {
    "id": "bb7c7c13"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ignaciomsarmiento/IAMD/blob/main/Clustering_Jerarquico/Clustering_Jerarquico_clase.ipynb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f061327",
   "metadata": {
    "id": "9f061327"
   },
   "source": [
    "# Segmentación de clientes basada en datos\n",
    "\n",
    "La segmentación de clientes es fundamental en el marketing moderno, permitiendo:\n",
    "\n",
    "1. Entender mejor los diferentes comportamientos de los clientes\n",
    "2. Crear estrategias de marketing más efectivas y personalizadas\n",
    "3. Optimizar recursos al dirigirse a grupos específicos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4758d5",
   "metadata": {},
   "source": [
    "\n",
    "## Análisis de clusters\n",
    "\n",
    "\n",
    "El análisis de clusters es una herramienta poderosa para identificar estos segmentos de mercado\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    <img src = \"figs/plot_clustering_notebook.png\" />\n",
    "</div>\n",
    "\n",
    "El análisis de clusters forma parte del Aprendizaje de Máquinas No Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab179f48",
   "metadata": {},
   "source": [
    "\n",
    "### Aprendizaje No Supervisado y Marketing Data Science\n",
    "\n",
    "Cuando pensamos en machine learning y IA, tendemos a visualizar redes neuronales complejas,  bosques aleatorios y otros algoritmos complejos. Si bien estos son métodos comunes de aprendizaje de máquinas, existe otra clase ampliamente utilizada pero distinta: el clustering o agrupamiento. \n",
    "\n",
    "El clustering, que se sitúa más apropiadamente en el aprendizaje no supervisado, permite explorar, aprender y resumir grandes cantidades de datos de manera eficiente. \n",
    "\n",
    "#### Componentes Clave del Aprendizaje No Supervisado\n",
    "\n",
    "Dos componentes clave son centrales al aprendizaje no supervisado. \n",
    "\n",
    "1. En el aprendizaje no supervisado, trabajamos con datos no etiquetados, lo que significa que las clases no están predeterminadas ni especificadas, y por lo tanto no hay un resultado esperado a predecir. \n",
    "\n",
    "2. El aprendizaje no supervisado excluye cualquier intervención significativa del analista durante el proceso de modelado. Esto contrasta con el aprendizaje supervisado, donde los parámetros del modelo se ajustan y los datos de entrenamiento son establecidos por el investigador, a menudo con propósitos predictivos. Con tales datos preprocesados y un resultado claro en mente, el ajuste del modelo y el output son relativamente fáciles de diagnosticar e inspeccionar. En el mundo del aprendizaje no supervisado, no hay una variable dependiente o resultado siendo predicho, ni hay parámetros a ajustar para resultar en modelos estadísticos más robustos usados para inferencia. Más bien, alimentamos datos no etiquetados a un algoritmo de aprendizaje y permitimos que emerjan patrones, típicamente basados en similitud entre observaciones (homogeneidad intra-grupo) y disimilitud entre agrupamientos de observaciones (heterogeneidad inter-grupo). \n",
    "\n",
    "Aunque existe un trade-off entre exploración (no supervisado) y confirmación (supervisado), es importante notar que cada uno es valioso en sus respectivas esferas, y pueden incluso fortalecerse mutuamente (Tukey, 1980). \n",
    "\n",
    "#### Aplicación en Marketing, clustering y segmentación de clientes \n",
    "\n",
    "\n",
    "El foco de este material, entonces, es el clustering, que es una de las formas más comunes de aprendizaje no supervisado. Los algoritmos de clustering varían ampliamente y son mut valiosos para dar sentido a datos a menudo grandes, difíciles de manejar, no etiquetados y no estructurados, detectando y mapeando grados de similitud entre objetos en algún espacio de características. Aunque es un dispositivo clave para simplificar la complejidad de los datos y revelar estructura subyacente, seleccionar y ajustar algoritmos de clustering puede ser complicado por un par de razones.\n",
    "\n",
    "Primero, en clustering típicamente no hay un algoritmo \"correcto\" o \"universal\" para una pregunta o problema. La selección de un algoritmo depende de una variedad de factores como el tamaño y estructura de los datos, los objetivos del analista, el nivel de expertise del dominio, la transformación de los datos, cómo se tratan las observaciones, etc. Como tal, el clustering es a menudo un proceso de seleccionar, ajustar, evaluar, repetir y luego comparar entre diferentes especificaciones de un solo algoritmo o entre múltiples algoritmos usando los mismos datos.\n",
    "\n",
    "\n",
    "Por ejemplo, supongamos que un analista está interesado en explorar y aprender sobre el comportamiento de compra de clientes de e-commerce. El analista, armado con un gran dataset no etiquetado de transacciones, historiales de navegación y datos demográficos, puede comenzar con clustering jerárquico para ver si existen agrupamientos entre los clientes. Usando output visual como un dendrograma (que se discute más adelante), puede revelar que tres o cuatro grupos amplios de clientes tienden a agruparse. Como punto de partida, el analista puede sospechar que estos clusters representan diferentes segmentos de mercado: compradores frecuentes de alto valor, compradores ocasionales sensibles al precio, window shoppers, y compradores por impulso.\n",
    "\n",
    "Independientemente de la calidad del supuesto, el analista puede aún estar inseguro de precisamente cómo y por qué existen estos clusters entre los clientes. El analista puede progresar a especificar un algoritmo más avanzado que requiera un poco más de información, como el algoritmo k-medias, asumiendo que existen tres o cuatro grupos basándose en el dendrograma jerárquico de la primera etapa. Si los resultados corroboran patrones similares revelando tres o cuatro grupos amplios, entonces el analista tiene un mejor sentido de que los datos pueden de hecho representar agrupamientos consecuentes en la población de clientes, que podrían ser segmentos de mercado distintos.\n",
    "\n",
    "Sin embargo, si hay clusters menos claramente definidos de la iteración k-medias cuando se asumieron tres clusters (basándose en la primera etapa de clustering jerárquico), entonces el analista puede querer actualizar el algoritmo para buscar dos o cinco clusters en lugar de tres. Además de la corroboración visual, el analista puede entonces aprovechar métodos comunes de validación interna para entender si estos algoritmos e iteraciones están apuntando a agrupamientos similares en la base de clientes.\n",
    "\n",
    "Una vez que el analista ha aprendido la estructura de los datos y los patrones, el analista puede desarrollar expectativas comprobables, estimar relaciones, y generar inferencias. Por ejemplo, una vez identificados los segmentos de clientes, podríamos:\n",
    "\n",
    "- Diseñar campañas de marketing personalizadas para cada segmento\n",
    "- Desarrollar modelos predictivos supervisados para clasificar nuevos clientes\n",
    "- Optimizar estrategias de pricing por segmento\n",
    "- Personalizar recomendaciones de productos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbf25b",
   "metadata": {},
   "source": [
    "\n",
    "<div >\n",
    "<img src = \"figs/RethinkSegmentation.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19c713",
   "metadata": {},
   "source": [
    "\n",
    "Existen principalmente dos enfoques para el clustering en clustering:\n",
    "\n",
    "1. Métodos basados en distancia: Agrupan clientes según su similitud\n",
    "2. Métodos basados en modelos: Utilizan modelos estadísticos para definir los segmentos\n",
    "\n",
    "\n",
    "La clave está en entender que no existe un método \"perfecto\", cada algoritmo tiene sus fortalezas y debilidades. La elección del método dependerá de:\n",
    "- Las características de nuestros datos\n",
    "- Los objetivos específicos de la segmentación\n",
    "- Los requisitos del negocio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c385d",
   "metadata": {
    "id": "b69c385d"
   },
   "source": [
    "### Etapas generales\n",
    "\n",
    "Las etapas del análisis de clusters podemos resumirlas de la siguiente forma:\n",
    "\n",
    "1. Iniciamos con una matriz de datos\n",
    "\n",
    "\\begin{align}\n",
    "    X_{n\\times k}=\\left(\\begin{array}{cccc}\n",
    "    x_{11} &  & \\dots & x_{1k}\\\\\n",
    "    \\\\\n",
    "    \\vdots &  & x_{ik} & \\vdots\\\\\n",
    "    \\\\\n",
    "    x_{n1} &  & \\dots & x_{nk}\n",
    "    \\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "2. Calculamos la matriz de distancia o disimilitud\n",
    "\n",
    "\\begin{align}\n",
    "D_{n\\times n}=\\left(\\begin{array}{ccccc}\n",
    "d_{11} &  & \\dots &  & d_{1n}\\\\\n",
    " & \\ddots\\\\\n",
    "\\vdots &  & d_{jj} &  & \\vdots\\\\\n",
    " &  &  & \\ddots\\\\\n",
    "d_{n1} &  & \\dots &  & d_{nn}\n",
    "\\end{array}\\right)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "3. Aplicamos el algoritmo de clustering. Existen varios tipos\n",
    "    - **basados en centroides**\n",
    "    - **basados en conectividad**\n",
    "    - **basados en densidades**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c63f4",
   "metadata": {
    "id": "1e1c63f4"
   },
   "source": [
    "## Clustering Jerárquico\n",
    "\n",
    "- El clustering jerárquico es especialmente útil cuando no existen expectativas sobre los patrones y estructuras subyacentes de los datos.\n",
    "\n",
    "\n",
    "- Los métodos de agrupamiento jerárquico son la forma más intuitiva de agrupar datos porque imitan la forma en que un humano abordaría la tarea de dividir un conjunto de n observaciones (consumidores) en k grupos (segmentos).\n",
    "\n",
    "    - Si el objetivo es tener un gran segmento de mercado (k = 1), la única solución posible es un gran segmento de mercado que contenga a todos los consumidores en los datos X.\n",
    "    - En el otro extremo, si el objetivo es tener tantos segmentos de mercado como consumidores en el conjunto de datos (k = n), el número de segmentos de mercado tiene que ser n, y cada segmento debe contener exactamente un consumidor.\n",
    "\n",
    "- Cada consumidor representa su propio grupo. El análisis de segmentación de mercado se produce entre esos dos extremos.\n",
    "\n",
    "\n",
    "\n",
    "<div >\n",
    "    <img src = \"figs/WallStreet.png\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "<div >\n",
    "    <img src = \"figs/Harrans.png\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "- Una característica atractiva es que no es necesario especificar el número de clusers a buscar a priori como en otros algoritmos\n",
    "\n",
    "\n",
    "- Este  mide la conectividad entre las observaciones en algún espacio de características o conjunto de datos.\n",
    "\n",
    "\n",
    "- Podemos usar los resultados para visualizar su similitud espacial entre sí en una variedad de niveles, típicamente en forma de dendrograma, que es una estructura similar a un árbol que muestra progresivamente las similitudes entre las observaciones.\n",
    "\n",
    "\n",
    "- En algunos casos puede informar a los otros métodos de clustering  basados en los patrones revelados. Por ejemplo, si el dendrograma revela dos grupos naturales, entonces una segunda etapa puede inicializar un algoritmo de k-medias con dos conglomerados. Al especificar el algoritmo de k-medias, podríamos comparar directamente la validez interna de ambos algoritmos  para determinar cuál es mejor para agrupar los datos a lo largo de una variedad de dimensiones (p. ej., conectividad, compacidad, etc.).\n",
    "\n",
    "\n",
    "- Hay dos tipos de agrupamiento jerárquico:\n",
    "  - Los métodos de agrupamiento jerárquico divisivo comienzan con el conjunto de datos completo X y lo dividen en dos segmentos de mercado en un primer paso. Luego, cada uno de los segmentos se divide nuevamente en dos segmentos. Este proceso continúa hasta que cada consumidor tiene su propio segmento de mercado.\n",
    "  - El agrupamiento jerárquico aglomerativo aborda la tarea desde el otro extremo. El punto de partida es que cada consumidor representa su propio segmento de mercado (n grupos únicos). Paso a paso, los dos segmentos de mercado más cercanos entre sí se fusionan hasta que el conjunto de datos completo forma un gran segmento de mercado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d26fe",
   "metadata": {
    "id": "ae8d26fe"
   },
   "source": [
    "### Enlaces\n",
    "\n",
    "- Los algoritmos de clustering jerárquico son únicos en el sentido de que requieren especificar:\n",
    "\n",
    "    - una medida de distancia\n",
    "    - un método de enlace o vinculación,\n",
    "\n",
    "\n",
    "- Por lo tanto, con nuestros datos de distancia estandarizados, podemos ajustar un algoritmo de agrupamiento jerárquico, pero como el algoritmo procede en forma de pares, debemos especificar con precisión cómo se unen estos pares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18167e-6b44-43d7-b718-ae845b8f350f",
   "metadata": {
    "id": "ba18167e-6b44-43d7-b718-ae845b8f350f"
   },
   "source": [
    "\n",
    "- El método de enlace es el mecanismo para determinar esto y hay muchos métodos de vinculación entre los que elegir:\n",
    "\n",
    "   - *Enlace simple*: También conocido como técnica del vecino más cercano; en este método combinamos los clusters, basándonos en los dos puntos más cercanos de cada cluster.\n",
    "   - *Enlace completo (complete linkage - CL)* :  El enlace completo o técnica del vecino más lejano, es lo opuesto al enlace simple y combina los clusters encontrando la distancia máxima entre las observaciones de los clusters\n",
    "   - *Enlace promedio de grupo (average )* :El enlace promedio de grupo utiliza la mínima distancia promedio entre los grupos. Es decir, calculamos todas las distancias entre pares de ambos clusters, y calculamos el promedio.\n",
    "  - *Enlace usando centroides (Centroid)* Este método usa la mínima distancia entre los centroides del cluster.\n",
    "  - *Enlace de Ward*  une los clusters más cercanos entre sí minimizando la varianza dentro de cada grupo, buscando que los elementos dentro de un mismo cluster sean lo más homogéneos posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e53e1-612e-4392-a03b-428f894c9e0f",
   "metadata": {
    "id": "2d4e53e1-612e-4392-a03b-428f894c9e0f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Crear dos clusters claros y separados\n",
    "np.random.seed(42)\n",
    "cluster1 = np.random.normal(loc=[-2, 0], scale=0.3, size=(10, 2))\n",
    "cluster2 = np.random.normal(loc=[2, 0], scale=0.3, size=(10, 2))\n",
    "X = np.vstack([cluster1, cluster2])\n",
    "\n",
    "# Calcular centroides\n",
    "centroid1 = np.mean(X[:10], axis=0)\n",
    "centroid2 = np.mean(X[10:], axis=0)\n",
    "\n",
    "# Encontrar los puntos más cercanos y más lejanos entre clusters\n",
    "distances = []\n",
    "for i in range(10):\n",
    "    for j in range(10, 20):\n",
    "        dist = np.linalg.norm(X[i] - X[j])\n",
    "        distances.append((dist, i, j))\n",
    "min_dist = min(distances)\n",
    "max_dist = max(distances)\n",
    "min_points = (X[min_dist[1]], X[min_dist[2]])\n",
    "max_points = (X[max_dist[1]], X[max_dist[2]])\n",
    "\n",
    "# Graficar cada tipo de enlace en gráficos separados\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 18))\n",
    "fig.suptitle('Tipos de Enlaces en Clustering Jerárquico', fontsize=16)\n",
    "\n",
    "# Single Linkage\n",
    "axs[0, 0].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[0, 0].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[0, 0].plot([min_points[0][0], min_points[1][0]],\n",
    "               [min_points[0][1], min_points[1][1]],\n",
    "               'g--', linewidth=2, label='Single Linkage')\n",
    "axs[0, 0].set_title('Single Linkage')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Complete Linkage\n",
    "axs[0, 1].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[0, 1].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[0, 1].plot([max_points[0][0], max_points[1][0]],\n",
    "               [max_points[0][1], max_points[1][1]],\n",
    "               'r--', linewidth=2, label='Complete Linkage')\n",
    "axs[0, 1].set_title('Complete Linkage')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Average Linkage\n",
    "axs[1, 0].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[1, 0].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "for i in range(3):  # Visualización de conexiones promedio entre pares representativos\n",
    "    axs[1, 0].plot([X[i, 0], X[10 + i, 0]], [X[i, 1], X[10 + i, 1]], 'purple', linestyle='--', linewidth=1, alpha=0.6)\n",
    "axs[1, 0].plot([centroid1[0], centroid2[0]], [centroid1[1], centroid2[1]], '--', color='purple', linewidth=2, label='Average Linkage')\n",
    "axs[1, 0].set_title('Average Linkage')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Centroid Linkage\n",
    "axs[1, 1].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[1, 1].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[1, 1].plot([centroid1[0], centroid2[0]],\n",
    "               [centroid1[1], centroid2[1]],\n",
    "               'k--', linewidth=2, label='Centroid Linkage')\n",
    "axs[1, 1].set_title('Centroid Linkage')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Ward Linkage\n",
    "axs[2, 0].scatter(X[:10, 0], X[:10, 1], c='blue', label='Cluster 1', s=100, alpha=0.6)\n",
    "axs[2, 0].scatter(X[10:, 0], X[10:, 1], c='red', label='Cluster 2', s=100, alpha=0.6)\n",
    "axs[2, 0].plot([centroid1[0], centroid2[0]], [centroid1[1], centroid2[1]], '--', color='orange', linewidth=2)\n",
    "axs[2, 0].plot([centroid1[0], (centroid1[0] + centroid2[0]) / 2], [centroid1[1], (centroid1[1] + centroid2[1]) / 2],\n",
    "               '--', color='orange', linewidth=1.5, label='Ward Linkage')\n",
    "axs[2, 0].set_title('Ward Linkage')\n",
    "axs[2, 0].legend()\n",
    "axs[2, 0].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Quitar el último subplot vacío\n",
    "axs[2, 1].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee515e31-b45e-4f28-837d-ef46a4de0241",
   "metadata": {
    "id": "ee515e31-b45e-4f28-837d-ef46a4de0241"
   },
   "source": [
    "   \n",
    "- Es importante señalar que, al igual que las medidas de distancia, no existe una guía en la literatura sobre cuál es el mejor método de enlace.\n",
    "\n",
    "\n",
    "- La selección del método de enlace generalmente depende de las preferencias específicas del problema o disciplina, por ejemplo, el enlace centroide es popular entre los genetistas y ward entre los economistas.\n",
    "\n",
    "\n",
    "- Se recomienda que se comparen varios métodos de enlace para descubrir patrones naturales de la manera más eficiente posible.\n",
    "\n",
    "\n",
    "- Es importante reiterar que solo los algoritmos jerárquicos requieren la especificación de un método de vinculación, sin embargo, todos los algoritmos de agrupamiento requieren la especificación y el cálculo de una distancia entre las observaciones.\n",
    "\n",
    "    - La medida de distancia determina cómo se definen la similitud y la diferencia en el espacio de características, mientras que el método de enlace determina cómo se unen los elementos únicos, que se convierten en grupos más grandes.\n",
    "\n",
    "    - Se requieren medidas tanto de enlace como de distancia para el agrupamiento jerárquico, mientras que solo se requieren medidas de distancia para todas las demás técnicas de agrupamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76862f5a-69fe-4c87-a687-7e562a821bf4",
   "metadata": {
    "id": "76862f5a-69fe-4c87-a687-7e562a821bf4"
   },
   "source": [
    "# Ejemplo: Segmentación de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completar código leer base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d502cb-7d93-4074-be55-b4278b49cdd3",
   "metadata": {
    "id": "79d502cb-7d93-4074-be55-b4278b49cdd3"
   },
   "source": [
    "### El dendograma\n",
    "\n",
    "\n",
    "El dendrograma es una representación gráfica del resultado del proceso de agrupamiento en forma de árbol. La construcción es relativamente sencilla y se hace de la siguiente forma:\n",
    "\n",
    "   1. En la parte inferior del gráfico se colocan las N observaciones iniciales.\n",
    "   2. La unión de elementos se representan por tres líneas rectas. Dos líneas son perpendiculares a los elementos que se van a unir, y su altura va a estar dada por la distancia que hay entre los elementos. La tercera línea, las une.\n",
    "   3. El proceso se repite hasta que todos los elementos están conectados por líneas rectas.\n",
    "\n",
    "Entonces cada vez que se fusionan dos elementos o clusters, el dendrograma muestra una conexión correspondiente al nivel de distancia/disimilitud en el que se produjo. Por lo tanto, si cortamos el dendrograma a un nivel de distancia dado, obtenemos un número de clusters existentes en ese nivel y los elementos que lo conforman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completar código dendograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2affc508-78f5-44ce-bd71-ce60384385c5",
   "metadata": {
    "id": "2affc508-78f5-44ce-bd71-ce60384385c5"
   },
   "source": [
    "##### Ejemplo:\n",
    "\n",
    "|   | 1  | 2  | 3 | 4 | 5 |\n",
    "|---|----|----|---|---|---|\n",
    "| **1** | 0  |    |   |   |   |\n",
    "| **2** | 9  | 0  |   |   |   |\n",
    "| **3** | 3  | 7  | 0 |   |   |\n",
    "| **4** | 6  | 5  | 9 | 0 |   |\n",
    "| **5** | 11 | 10 | 2 | 8 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f4bc6-5605-4403-8a37-24fe8c3f8d23",
   "metadata": {
    "id": "088f4bc6-5605-4403-8a37-24fe8c3f8d23"
   },
   "source": [
    "<div >\n",
    "<img src = \"figs/complete_link0.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b6801-ab65-471d-82d6-37191f169f03",
   "metadata": {
    "id": "4b9b6801-ab65-471d-82d6-37191f169f03"
   },
   "source": [
    "|    | 35 | 1 | 2 | 4 |\n",
    "|----|----|---|---|---|\n",
    "| **35** | 0  |   |   |   |\n",
    "| **1** | 11 | 0 |   |   |\n",
    "| **2** | 10 | 9 | 0 |   |\n",
    "| **4** | 9  | 6 | 5 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ecfa7-cdb2-47cb-aa50-dd8115607c6a",
   "metadata": {
    "id": "682ecfa7-cdb2-47cb-aa50-dd8115607c6a"
   },
   "source": [
    "<div >\n",
    "<img src = \"figs/complete_link1.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b09a46-7d81-4b4d-8e5d-d7156bce3130",
   "metadata": {
    "id": "f1b09a46-7d81-4b4d-8e5d-d7156bce3130"
   },
   "source": [
    "<div >\n",
    "<img src = \"figs/complete_link.png\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce13d8c-272e-4937-9cb5-c349d9ba6801",
   "metadata": {
    "id": "fce13d8c-272e-4937-9cb5-c349d9ba6801"
   },
   "source": [
    "**enlace simple**\n",
    "\n",
    "  <div >\n",
    "<img src = \"figs/single_link.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5e1c0-8ada-40b3-ab25-27d438cc6bf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "aec5e1c0-8ada-40b3-ab25-27d438cc6bf1",
    "outputId": "a2d5137f-86b3-4cd8-e09d-4a5c86fd9e33"
   },
   "outputs": [],
   "source": [
    "# fijar distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c9720-2c1f-4572-a410-991039b1dbaf",
   "metadata": {
    "id": "d99c9720-2c1f-4572-a410-991039b1dbaf"
   },
   "outputs": [],
   "source": [
    "# Crear un gráfico de dispersión de los datos con los clusters coloreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72846ea-285a-43e7-a02d-dfae74d97c75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "f72846ea-285a-43e7-a02d-dfae74d97c75",
    "outputId": "d95a1f6e-9b99-44c4-f49d-bc00b1bca14a"
   },
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
